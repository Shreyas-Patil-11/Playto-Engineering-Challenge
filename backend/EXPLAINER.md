# Community Feed - Technical Explainer

## The Tree: Nested Comments Implementation

### Database Model

Comments are stored in a **flat table** with a self-referential foreign key (`parent_id`) to support threading:

```python
class Comment(models.Model):
    post = models.ForeignKey(Post, on_delete=models.CASCADE, related_name='comments')
    parent = models.ForeignKey('self', on_delete=models.CASCADE, null=True, blank=True, related_name='replies')
    author = models.ForeignKey(User, on_delete=models.CASCADE)
    content = models.TextField(max_length=1000)
    likes_count = models.PositiveIntegerField(default=0)
    created_at = models.DateTimeField(auto_now_add=True)
```

### The N+1 Problem Solution

Instead of recursively fetching replies (which would cause N+1 queries), we:

1. **Fetch ALL comments for a post in ONE query:**

```python
# Single query - fetches all comments regardless of nesting depth
comments = Comment.objects.filter(
    post_id=post_id
).select_related('author').order_by('created_at')
```

2. **Build the tree in application memory (O(n) complexity):**

```python
def build_comment_tree(comments, user=None, user_liked_ids=None):
    """
    Build nested tree from flat list.
    Time: O(n), Space: O(n)
    """
    comment_map = {}
    root_comments = []
    
    # First pass: Create map and initialize replies
    for comment in comments:
        comment._prefetched_replies = []
        comment._liked_by_user = comment.id in (user_liked_ids or set())
        comment_map[comment.id] = comment
    
    # Second pass: Build tree structure
    for comment in comments:
        if comment.parent_id is None:
            root_comments.append(comment)
        else:
            parent = comment_map.get(comment.parent_id)
            if parent:
                parent._prefetched_replies.append(comment)
    
    return root_comments
```

### Query Count Comparison

| Approach | Query Count (50 nested comments) |
|----------|----------------------------------|
| Naive recursive | 50+ queries |
| Our approach | **2 queries** (1 for comments, 1 for user likes) |

---

## The Math: 24-Hour Leaderboard Query

### The Requirement

Calculate the top 5 users by karma earned **in the last 24 hours only**, without storing a "daily_karma" field.

### The Solution: KarmaTransaction Table

Every karma-earning event is logged as a transaction:

```python
class KarmaTransaction(models.Model):
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    amount = models.IntegerField()  # +5 for post like, +1 for comment like
    reason = models.CharField(max_length=20)  # 'post_like' or 'comment_like'
    source_id = models.PositiveIntegerField()
    created_at = models.DateTimeField(default=timezone.now)
```

### The QuerySet

```python
from datetime import timedelta
from django.db.models import Sum
from django.db.models.functions import Coalesce
from django.utils import timezone

twenty_four_hours_ago = timezone.now() - timedelta(hours=24)

leaderboard = KarmaTransaction.objects.filter(
    created_at__gte=twenty_four_hours_ago
).values(
    'user_id'
).annotate(
    karma_24h=Coalesce(Sum('amount'), 0)
).filter(
    karma_24h__gt=0
).order_by(
    '-karma_24h'
)[:5]
```

### The Generated SQL

```sql
SELECT 
    user_id, 
    COALESCE(SUM(amount), 0) AS karma_24h
FROM karma_transactions
WHERE created_at >= NOW() - INTERVAL '24 hours'
GROUP BY user_id
HAVING COALESCE(SUM(amount), 0) > 0
ORDER BY karma_24h DESC
LIMIT 5;
```

### Why This Works

1. **Dynamic Calculation**: Karma is always fresh - no stale cached values
2. **Accurate Time Window**: Uses database timestamps, not application clock
3. **Scalable**: Single aggregation query, indexed on `created_at`
4. **Flexible**: Easy to change time window (7 days, 1 hour, etc.)

---

## The AI Audit: Bug Found and Fixed

### The Problem

When I asked the AI to implement the like functionality with race condition protection, it initially generated this code:

```python
# BUGGY CODE - Generated by AI
@action(detail=True, methods=['post'])
def like(self, request, pk=None):
    post = Post.objects.get(pk=pk)
    
    # Check if already liked
    if Like.objects.filter(user=request.user, target_id=post.id).exists():
        return Response({'error': 'Already liked'})
    
    # Create like
    Like.objects.create(user=request.user, target_id=post.id)
    
    # Update count
    post.likes_count += 1
    post.save()
    
    return Response({'success': True})
```

### The Bugs

1. **Race Condition**: Between the `exists()` check and `create()`, another request could slip through
2. **Non-Atomic Counter Update**: `post.likes_count += 1; post.save()` is not atomic - concurrent requests could overwrite each other
3. **No Transaction**: Operations should be wrapped in a transaction for consistency

### The Fix

```python
# FIXED CODE
@action(detail=True, methods=['post'])
def like(self, request, pk=None):
    try:
        with transaction.atomic():
            # Lock the row to prevent concurrent modifications
            post = Post.objects.select_for_update().get(pk=pk)
            
            # Check inside transaction
            if Like.objects.filter(
                user=request.user,
                target_type=Like.TARGET_POST,
                target_id=post.id
            ).exists():
                return Response(
                    {'error': 'Already liked'},
                    status=status.HTTP_400_BAD_REQUEST
                )
            
            # Create like (unique constraint as backup)
            Like.objects.create(
                user=request.user,
                target_type=Like.TARGET_POST,
                target_id=post.id
            )
            
            # Atomic counter update using F() expression
            Post.objects.filter(pk=pk).update(
                likes_count=F('likes_count') + 1
            )
            
            return Response({'success': True})
            
    except IntegrityError:
        # Unique constraint caught a race condition
        return Response(
            {'error': 'Already liked'},
            status=status.HTTP_400_BAD_REQUEST
        )
```

### Key Improvements

| Issue | AI Code | Fixed Code |
|-------|---------|------------|
| Row Locking | ❌ None | ✅ `select_for_update()` |
| Transaction | ❌ None | ✅ `transaction.atomic()` |
| Atomic Update | ❌ `post.save()` | ✅ `F('likes_count') + 1` |
| Backup Constraint | ❌ None | ✅ `unique_together` on Like model |
| Error Handling | ❌ None | ✅ `IntegrityError` catch |

---

## Additional Technical Decisions

### 1. Like Model Design

Instead of separate `PostLike` and `CommentLike` models, we use a single `Like` model with `target_type`:

```python
class Like(models.Model):
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    target_type = models.CharField(max_length=10)  # 'post' or 'comment'
    target_id = models.PositiveIntegerField()
    
    class Meta:
        unique_together = ['user', 'target_type', 'target_id']
```

**Pros**: Single table, simpler queries, extensible to new target types
**Cons**: No foreign key integrity (handled at application level)

### 2. Karma Transaction Logging

We log karma changes (not just current totals) because:

1. **Auditability**: Can track who gave karma and when
2. **Time-based Queries**: Enable 24h/7d/30d leaderboards
3. **Flexibility**: Can implement karma decay, caps, etc.
4. **Debugging**: Easy to investigate karma anomalies

### 3. Caching Strategy (Production)

For production, the leaderboard query should be cached:

```python
from django.core.cache import cache

def get_leaderboard():
    cache_key = 'leaderboard_24h'
    result = cache.get(cache_key)
    
    if result is None:
        result = calculate_leaderboard()  # The expensive query
        cache.set(cache_key, result, timeout=60)  # 1 minute TTL
    
    return result
```

---

## Testing the Technical Constraints

The test suite (`feed/tests.py`) includes specific tests for:

1. **Leaderboard Calculation**: Verifies only 24h transactions are counted
2. **Comment Tree Building**: Ensures O(n) complexity with no extra queries
3. **Race Condition Prevention**: Tests unique constraint and atomic operations

Run tests with:

```bash
python manage.py test feed
```
